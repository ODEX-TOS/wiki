<!--
    title: Intel_GVT-g
    description: Migration of Intel_GVT-g from the arch Wiki to the TOS Wiki
    published: true
    date: 2020-05-28T17:44:33.000Z
    tags: 
    -->>

<div id="content" class="mw-body" role="main" style="margin: 0">
	<a id="top"></a>
	
	<div class="mw-indicators mw-body-content">
</div>

	<h1 id="firstHeading"  lang="en">Intel GVT-g</h1>
	
	<div id="bodyContent" class="mw-body-content">
		<div id="siteSub" >From TOS Wiki</div>
		<div id="contentSub"></div>
		
		
		
		<div id="jump-to-nav"></div>
		<a class="mw-jump-link" href="#mw-head">Jump to navigation</a>
		<a class="mw-jump-link" href="#p-search">Jump to search</a>
		<div id="mw-content-text" lang="en" dir="ltr" class="mw-content-ltr"><div class="mw-parser-output">
<div class="archwiki-template-meta-related-articles-start">
<p>Related articles</p>
<ul>
<li><a href="../PCI_passthrough_via_OVMF.html" title="PCI passthrough via OVMF">PCI passthrough via OVMF</a></li>
<li><a href="../QEMU.html" title="QEMU">QEMU</a></li>
<li><a href="../Intel_graphics.html" title="Intel graphics">Intel graphics</a></li>
</ul>
</div>
<p><a rel="nofollow"  href="https://github.com/intel/gvt-linux/wiki/GVTg_Setup_Guide">Intel GVT-g</a> is a technology that provides mediated device passthrough for Intel GPUs (Broadwell and newer). It can be used to virtualize the GPU for multiple guest VMs, effectively providing near-native graphics performance in the VM and still letting your host use the virtualized GPU normally. This is useful if you want accelerated graphics in Windows VMs running on ultrabooks without dedicated GPUs for <a href="../PCI_passthrough_via_OVMF.html" title="PCI passthrough via OVMF">full device passthrough</a>. (Similar technologies exist for NVIDIA and AMD GPUs, but they're available only in the "professional" GPU lines like Quadro, Radeon Pro and so on.)
</p>
<p>There is also a variant of this technology called GVT-d - it is essentially Intel's name for full device passthrough with the vfio-pci driver. With GVT-d, the host cannot use the virtualized GPU.
</p>
<div id="toc" >
<input type="checkbox" role="button" id="toctogglecheckbox"  style="display:none"><div  lang="en" dir="ltr">
<h2>Contents</h2>
<span ><label  for="toctogglecheckbox"></label></span>
</div>
<ul>
<li class="toclevel-1 tocsection-1">
<a href="#Prerequisite"><span >1</span> <span >Prerequisite</span></a>
<ul>
<li class="toclevel-2 tocsection-2"><a href="#libvirt_qemu_hook"><span >1.1</span> <span >libvirt qemu hook</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-3">
<a href="#Assign_vGPU_to_VM"><span >2</span> <span >Assign vGPU to VM</span></a>
<ul>
<li class="toclevel-2 tocsection-4"><a href="#QEMU_CLI"><span >2.1</span> <span >QEMU CLI</span></a></li>
<li class="toclevel-2 tocsection-5"><a href="#libvirt"><span >2.2</span> <span >libvirt</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-6">
<a href="#Getting_vGPU_display_contents"><span >3</span> <span >Getting vGPU display contents</span></a>
<ul>
<li class="toclevel-2 tocsection-7">
<a href="#Using_DMA-BUF_display"><span >3.1</span> <span >Using DMA-BUF display</span></a>
<ul>
<li class="toclevel-3 tocsection-8"><a href="#QEMU_CLI_2"><span >3.1.1</span> <span >QEMU CLI</span></a></li>
<li class="toclevel-3 tocsection-9"><a href="#libvirt_2"><span >3.1.2</span> <span >libvirt</span></a></li>
</ul>
</li>
<li class="toclevel-2 tocsection-10">
<a href="#Using_DMA-BUF_with_UEFI/OVMF"><span >3.2</span> <span >Using DMA-BUF with UEFI/OVMF</span></a>
<ul>
<li class="toclevel-3 tocsection-11"><a href="#libvirt_3"><span >3.2.1</span> <span >libvirt</span></a></li>
</ul>
</li>
<li class="toclevel-2 tocsection-12">
<a href="#Enable_RAMFB_display_(optional)"><span >3.3</span> <span >Enable RAMFB display (optional)</span></a>
<ul>
<li class="toclevel-3 tocsection-13"><a href="#QEMU_CLI_3"><span >3.3.1</span> <span >QEMU CLI</span></a></li>
<li class="toclevel-3 tocsection-14"><a href="#libvirt_4"><span >3.3.2</span> <span >libvirt</span></a></li>
</ul>
</li>
</ul>
</li>
<li class="toclevel-1 tocsection-15">
<a href="#Display_vGPU_output"><span >4</span> <span >Display vGPU output</span></a>
<ul>
<li class="toclevel-2 tocsection-16"><a href="#Output_using_QEMU_display_(QEMU_CLI_only)"><span >4.1</span> <span >Output using QEMU display (QEMU CLI only)</span></a></li>
<li class="toclevel-2 tocsection-17">
<a href="#Output_using_SPICE_with_MESA_EGL"><span >4.2</span> <span >Output using SPICE with MESA EGL</span></a>
<ul>
<li class="toclevel-3 tocsection-18"><a href="#QEMU_CLI_4"><span >4.2.1</span> <span >QEMU CLI</span></a></li>
<li class="toclevel-3 tocsection-19"><a href="#libvirt_5"><span >4.2.2</span> <span >libvirt</span></a></li>
</ul>
</li>
<li class="toclevel-2 tocsection-20">
<a href="#Output_using_SPICE_with_NVIDIA_EGL_or_VNC"><span >4.3</span> <span >Output using SPICE with NVIDIA EGL or VNC</span></a>
<ul>
<li class="toclevel-3 tocsection-21"><a href="#libvirt_6"><span >4.3.1</span> <span >libvirt</span></a></li>
</ul>
</li>
<li class="toclevel-2 tocsection-22">
<a href="#Disable_all_outputs"><span >4.4</span> <span >Disable all outputs</span></a>
<ul>
<li class="toclevel-3 tocsection-23"><a href="#QEMU_CLI_5"><span >4.4.1</span> <span >QEMU CLI</span></a></li>
<li class="toclevel-3 tocsection-24"><a href="#libvirt_7"><span >4.4.2</span> <span >libvirt</span></a></li>
</ul>
</li>
</ul>
</li>
<li class="toclevel-1 tocsection-25">
<a href="#Troubleshooting"><span >5</span> <span >Troubleshooting</span></a>
<ul>
<li class="toclevel-2 tocsection-26"><a href="#Missing_mdev_supported_types_directory"><span >5.1</span> <span >Missing mdev_supported_types directory</span></a></li>
<li class="toclevel-2 tocsection-27"><a href="#Windows_hanging_with_bad_memory_error"><span >5.2</span> <span >Windows hanging with bad memory error</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-28"><a href="#See_also"><span >6</span> <span >See also</span></a></li>
</ul>
</div>

<h2><span class="mw-headline" id="Prerequisite">Prerequisite</span></h2>
<p>You'll have to create a virtual GPU (vGPU) first, then assign it to your VM. The guest with a vGPU sees it as a "regular" GPU - just install the latest native drivers. (The vGPU actually does need specialized drivers to work correctly, but all the required changes are present in the latest upstream Linux/Windows drivers.)
</p>
<p>You'll need to:
</p>
<ul>
<li>Use at least Linux 4.16 and <a href="../QEMU.html" title="QEMU">QEMU</a> 2.12.</li>
<li>Enable IOMMU by adding <code>intel_iommu=on</code> to your <a href="../Kernel_parameters.html" title="Kernel parameters">kernel parameters</a>.</li>
<li>
<a href="../Kernel_module.html#Automatic_module_loading_with_systemd" title="Kernel module">Enable</a> kernel modules: <code>kvmgt</code>, <code>vfio-iommu-type1</code> and <code>vfio-mdev</code>.</li>
<li>
<a href="../Kernel_module.html#Setting_module_options" title="Kernel module">Set</a> i915 module parameter <code>enable_gvt=1</code> to enable GPU virtualization.</li>
<li>Find the PCI address and domain number of your GPU (<code>$GVT_PCI</code> and <code>$GVT_DOM</code> in commands below), as it resides in <code>/sys/bus/pci/devices</code>. It looks like this: <code>0000:00:02.0</code> - you can look it up by running <code>lspci -D -nn</code>, looking for <code>VGA compatible controller: Intel Corporation HD Graphics ...</code> and noting down the address on the left.</li>
<li>Generate the vGPU GUID (<code>$GVT_GUID</code> in commands below) which you'll use to create and assign the vGPU. A single virtual GPU can be assigned only to a single VM - create as many GUIDs as you want vGPUs. (You can do so by running <code>uuidgen</code>.)</li>
</ul>
<p>After rebooting with the <code>i915.enable_gvt=1</code> flag, you should be able to create vGPUs - there are multiple vGPU types you can create, which mainly differ in the amount of resources dedicated to that vGPU. You can look up what types are available in your system (and <code>cat description</code> inside of each type to discover what it's capable of) like this:
</p>
<pre># ls /sys/devices/pci${GVT_DOM}/$GVT_PCI/mdev_supported_types
i915-GVTg_V5_1  # Video memory: &lt;512MB, 2048MB&gt;, resolution: up to 1920x1200
i915-GVTg_V5_2  # Video memory: &lt;256MB, 1024MB&gt;, resolution: up to 1920x1200
i915-GVTg_V5_4  # Video memory: &lt;128MB, 512MB&gt;, resolution: up to 1920x1200
i915-GVTg_V5_8  # Video memory: &lt;64MB, 384MB&gt;, resolution: up to 1024x768
</pre>
<p>Pick a type you want to use - we'll refer to it as <code>$GVT_TYPE</code> below. Use the GUID you've created to create a vGPU with a chosen type:
</p>
<pre># echo "$GVT_GUID" &gt; "/sys/devices/pci${GVT_DOM}/$GVT_PCI/mdev_supported_types/$GVT_TYPE/create"
</pre>
<p>You can repeat this as many times as you want with different GUIDs. All created vGPUs will land in <code>/sys/bus/pci/devices/$GVT_PCI/</code> - if you'd like to remove a vGPU, you can do:
</p>
<pre># echo 1 &gt; /sys/bus/pci/devices/$GVT_PCI/$GVT_GUID/remove
</pre>
<h3><span class="mw-headline" id="libvirt_qemu_hook">libvirt qemu hook</span></h3>
<p>With libvirt, a <a rel="nofollow"  href="https://www.libvirt.org/hooks.html">libvirt qemu hook</a> can be used to automatically create the vGPU when the machine is started, and to remove it when the machine is stopped. Replace the variables with the values you found above and the DOMAIN with the name of the machine.
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">/etc/libvirt/hooks/qemu</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">#!/bin/bash
GVT_PCI=&lt;GVT_PCI&gt;
GVT_GUID=&lt;GVT_GUID&gt;
MDEV_TYPE=&lt;GVT_TYPE&gt;
DOMAIN=&lt;DOMAIN name&gt;
if [ $# -ge 3 ]; then
    if [ $1 = "$DOMAIN" -a $2 = "prepare" -a $3 = "begin" ]; then
        echo "$GVT_GUID" &gt; "/sys/bus/pci/devices/$GVT_PCI/mdev_supported_types/$MDEV_TYPE/create"
    elif [ $1 = "$DOMAIN" -a $2 = "release" -a $3 = "end" ]; then
        echo 1 &gt; /sys/bus/pci/devices/$GVT_PCI/$GVT_GUID/remove
    fi
fi</pre>
<div class="archwiki-template-box archwiki-template-box-note">
<strong>Note:</strong> If you use libvirt user session, you need to tweak the script to use privilege escalation commands, such as <code>pkexec</code> or a no-password <code>sudo</code>.</div>
<div class="archwiki-template-box archwiki-template-box-note">
<strong>Note:</strong> The XML of the domain is feed to the hook script through stdin. You can use <code>xmllint</code> and XPath expression to extract <code>GVT_GUID</code> from stdin, e.g.:
<pre>GVT_GUID="$(xmllint --xpath 'string(/domain/devices/hostdev[@type="mdev"][@display="on"]/source/address/@uuid)' -)"</pre>
</div>
<h2><span class="mw-headline" id="Assign_vGPU_to_VM">Assign vGPU to VM</span></h2>
<p>If you run <code>qemu</code> or <code>libvirtd</code> as a regular user, it may complain that some path <code>/dev/vfio/[number]</code> is not writeable. You need to enable write access to that path for the account, with <code>chmod</code> or <code>setfacl</code>.
</p>
<h4><span class="mw-headline" id="QEMU_CLI">QEMU CLI</span></h4>
<div class="archwiki-template-box archwiki-template-box-note">
<strong>Note:</strong> KVM must be enabled by <code>-enable-kvm</code>.</div>
<p>To create a VM with the virtualized GPU, add this parameter to the QEMU command line:
</p>
<pre>-device vfio-pci,sysfsdev=/sys/bus/mdev/devices/$GVT_GUID
</pre>
<h4><span class="mw-headline" id="libvirt">libvirt</span></h4>
<p>Add the following device to the <code>&lt;devices&gt;</code> element of the VM definition:
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">$ virsh edit [vmname]</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">...
    &lt;hostdev mode='subsystem' type='mdev' managed='no' model='vfio-pci' display='off'&gt;
      &lt;source&gt;
        &lt;address uuid='<b>GVT_GUID'</b>/&gt;
      &lt;/source&gt;
    &lt;/hostdev&gt;
...</pre>
<p>Replace <b>GVT_GUID</b> with the UUID of your vGPU.
</p>
<h2><span class="mw-headline" id="Getting_vGPU_display_contents">Getting vGPU display contents</span></h2>
<p>There are several possible ways to retrieve the display contents from the vGPU.
</p>
<h3><span class="mw-headline" id="Using_DMA-BUF_display">Using DMA-BUF display</span></h3>
<div class="archwiki-template-box archwiki-template-box-warning">
<strong>Warning:</strong> According to this <a rel="nofollow"  href="https://github.com/intel/gvt-linux/issues/20">issue</a>, this method will not work with UEFI guests using (unmodified) OVMF. See below for patches/workarounds. </div>
<h4><span class="mw-headline" id="QEMU_CLI_2">QEMU CLI</span></h4>
<p>Add <code>display=on,x-igd-opregion=on</code> to the end of <code>-device vfio-pci</code> parameter, e.g.:
</p>
<pre> -device vfio-pci,sysfsdev=/sys/bus/mdev/devices/$GVT_GUID,display=on,x-igd-opregion=on
</pre>
<h4><span class="mw-headline" id="libvirt_2">libvirt</span></h4>
<p>First, modify the XML schema of the VM definition so that we can use QEMU-specific elements later. Change
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">$ virsh edit [vmname]</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">&lt;domain type='kvm'&gt;
</pre>
<p>to
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">$ virsh edit [vmname]</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">&lt;domain type='kvm' xmlns:qemu='http://libvirt.org/schemas/domain/qemu/1.0'&gt;
</pre>
<p>Then add this configuration to the end of the <code>&lt;domain&gt;</code> element, i. e. insert this text right above the closing <code>&lt;/domain&gt;</code> tag:
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">$ virsh edit [vmname]</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">...
  &lt;qemu:commandline&gt;
    &lt;qemu:arg value='-set'/&gt;
    &lt;qemu:arg value='device.hostdev0.x-igd-opregion=on'/&gt;
 &lt;/qemu:commandline&gt;
...
</pre>
<h3>
<span id="Using_DMA-BUF_with_UEFI.2FOVMF"></span><span class="mw-headline" id="Using_DMA-BUF_with_UEFI/OVMF">Using DMA-BUF with UEFI/OVMF</span>
</h3>
<p>As stated above, DMA-BUF display will not work with UEFI-based guests using (unmodified) OVMF because it won't create the necessary ACPI OpRegion exposed via QEMU's nonstandard fw_cfg interface. See <a rel="nofollow"  href="https://bugzilla.tianocore.org/show_bug.cgi?id=935">this OVMF bug</a> for details of this issue.
</p>
<p>According to <a rel="nofollow"  href="https://github.com/intel/gvt-linux/issues/23#issuecomment-468125999">this GitHub comment</a>, the OVMF bug report suggests several solutions to the problem. It is possible to:
</p>
<ul>
<li>
<a rel="nofollow"  href="https://bugzilla.tianocore.org/attachment.cgi?id=165">patch</a> OVMF (<a rel="nofollow"  href="https://bugzilla.tianocore.org/show_bug.cgi?id=935#c4">details</a>) to add an Intel-specific quirk (most straightforward but non-upstreamable solution);</li>
<li>
<a rel="nofollow"  href="https://bugzilla.tianocore.org/attachment.cgi?id=168">patch</a> the host kernel (<a rel="nofollow"  href="https://bugzilla.tianocore.org/show_bug.cgi?id=935#c12">details</a>) to automatically provide an option ROM for the vGPU containing basically the same code but in option ROM format;</li>
<li>
<a rel="nofollow"  href="http://120.25.59.132:3000/vbios_gvt_uefi.rom">extract the OpROM</a> from the kernel patch (<a rel="nofollow"  href="https://www.reddit.com/r/VFIO/comments/av736o/creating_a_clover_bios_nonuefi_install_for_qemu/ehdz6mf/">source</a>) and feed it to QEMU as an override.</li>
</ul>
<p>We will go with the last option because it does not involve patching anything. (Note: if the link goes down, the OpROM can be extracted from the kernel patch by hand.)
</p>
<p>Download <code>vbios_gvt_uefi.rom</code> and place it somewhere world-accessible (we will use <code>/</code> to make an example).
</p>
<h4><span class="mw-headline" id="libvirt_3">libvirt</span></h4>
<p>Then edit the VM definition, appending this configuration to the <code>&lt;qemu:commandline&gt;</code> element we added earlier:
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">$ virsh edit [vmname]</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">...
    &lt;qemu:arg value='-set'/&gt;
    &lt;qemu:arg value='device.hostdev0.romfile=<b>/vbios_gvt_uefi.rom</b>'/&gt;
...
</pre>
<h3>
<span id="Enable_RAMFB_display_.28optional.29"></span><span class="mw-headline" id="Enable_RAMFB_display_(optional)">Enable RAMFB display (optional)</span>
</h3>
<p>This should be combined with the above DMA-BUF configuration in order to also display everything that happens before the guest Intel driver is loaded (i.e. POST, the firmware interface, and the guest initialization).
</p>
<h4><span class="mw-headline" id="QEMU_CLI_3">QEMU CLI</span></h4>
<p>Add <code>ramfb=on,driver=vfio-pci-nohotplug</code> to the end of <code>-device vfio-pci</code> parameter, e.g.:
</p>
<pre>-device vfio-pci,sysfsdev=/sys/bus/mdev/devices/$GVT_GUID,display=on,x-igd-opregion=on,ramfb=on,driver=vfio-pci-nohotplug</pre>
<h4><span class="mw-headline" id="libvirt_4">libvirt</span></h4>
<p>First, follow the first step of <a href="#libvirt_2">this section</a> to modify the XML schema.
</p>
<p>Then add this configuration to the end of the <code>&lt;domain&gt;</code> element, i.e. insert this text right above the closing <code>&lt;/domain&gt;</code> tag:
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">$ virsh edit [vmname]</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">...
 &lt;qemu:commandline&gt;
    &lt;qemu:arg value='-set'/&gt;
    &lt;qemu:arg value='device.hostdev0.ramfb=on'/&gt;
    &lt;qemu:arg value='-set'/&gt;
    &lt;qemu:arg value='device.hostdev0.driver=vfio-pci-nohotplug'/&gt;
 &lt;/qemu:commandline&gt;
...
</pre>
<h2><span class="mw-headline" id="Display_vGPU_output">Display vGPU output</span></h2>
<p>Due to an <a rel="nofollow"  href="https://gitlab.freedesktop.org/spice/spice-gtk/issues/100">issue</a> with spice-gtk, the configuration is different depending on the SPICE client EGL implementation.
</p>
<h3>
<span id="Output_using_QEMU_display_.28QEMU_CLI_only.29"></span><span class="mw-headline" id="Output_using_QEMU_display_(QEMU_CLI_only)">Output using QEMU display (QEMU CLI only)</span>
</h3>
<p>Add <code>-display gtk,gl=on</code> to the command line. The QEMU VGA adapter can be disabled by adding <code>-vga none</code>, or you have two virtual screens, and the one connected to the QEMU VGA adapter is blank.
</p>
<h3><span class="mw-headline" id="Output_using_SPICE_with_MESA_EGL">Output using SPICE with MESA EGL</span></h3>
<h4><span class="mw-headline" id="QEMU_CLI_4">QEMU CLI</span></h4>
<p>Add <code>-display spice-app,gl=on</code> to the command line. <code>virt-viewer</code> must be installed.
</p>
<h4><span class="mw-headline" id="libvirt_5">libvirt</span></h4>
<ol>
<li>Ensure the above added &lt;hostdev&gt; device have the display attribute set to 'on'.</li>
<li>Remove all &lt;graphics&gt; and &lt;video&gt; devices.</li>
<li>Add the following devices:</li>
</ol>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">$ virsh edit [vmname]</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">...
    &lt;graphics type='spice'&gt;
      &lt;listen type='none'/&gt;
      &lt;gl enable='yes'/&gt;
    &lt;/graphics&gt;
    &lt;video&gt;
      &lt;model type='none'/&gt;
    &lt;/video&gt;
...
</pre>
<p>The is an optional attribute <code>rendernode</code> in the <code>gl</code> tag to allow specify the renderer, e.g.:
</p>
<pre> &lt;gl enable='yes' rendernode='/dev/dri/by-path/pci-0000:00:02.0-render'/&gt;
</pre>
<h3><span class="mw-headline" id="Output_using_SPICE_with_NVIDIA_EGL_or_VNC">Output using SPICE with NVIDIA EGL or VNC</span></h3>
<h4><span class="mw-headline" id="libvirt_6">libvirt</span></h4>
<ol>
<li>Ensure the above added &lt;hostdev&gt; device have the display attribute set to 'on'.</li>
<li>Remove all &lt;graphics&gt; and &lt;video&gt; devices.</li>
<li>Add the following devices:</li>
</ol>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">$ virsh edit [vmname]</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">...
    &lt;graphics type='spice' autoport='yes'&gt;
      &lt;listen type='address'/&gt;
    &lt;/graphics&gt;
    &lt;graphics type='egl-headless'/&gt;
    &lt;video&gt;
      &lt;model type='none'/&gt;
    &lt;/video&gt;
...
</pre>
<p>The <code>&lt;graphics type='spice'&gt;</code> type can be changed to 'vnc' to use VNC instead.
</p>
<p>Also there is an <i>optional</i> tag &lt;gl&gt; inside &lt;graphics type='egl-headless'&gt; tag to force a specific renderer, do not put inside the 'spice' graphics due the mentioned bug, example:
</p>
<pre>   &lt;graphics type='egl-headless'&gt;
     &lt;gl rendernode='/dev/dri/by-path/pci-0000:00:02.0-render'/&gt;
   &lt;/graphics&gt;
</pre>
<h3><span class="mw-headline" id="Disable_all_outputs">Disable all outputs</span></h3>
<p>If all outputs are disabled, the only way to see the display output would then be using a software server like RDP, VNC or Looking Glass.
To see more details in <a href="../PCI_passthrough_via_OVMF.html#Using_Looking_Glass_to_stream_guest_screen_to_the_host" title="PCI passthrough via OVMF">using Looking Glass to stream guest screen to the host</a>.
</p>
<h4><span class="mw-headline" id="QEMU_CLI_5">QEMU CLI</span></h4>
<p>In the <code>-device vfio-pci</code> parameter, remove <code>ramfb=on</code> and change to <code>display=off</code>. Add <code>-vga none</code> to disable the QEMU VGA adapter.
</p>
<h4><span class="mw-headline" id="libvirt_7">libvirt</span></h4>
<p>To ensure no emulated GPU is added, one can edit the VM configuration and do the following changes:
</p>
<ol>
<li>Remove all &lt;graphics&gt; devices.</li>
<li>Change the &lt;video&gt; device to be type 'none'.</li>
<li>Ensure the above added &lt;hostdev&gt; device have the <code>display</code> attribute set to 'off'.</li>
</ol>
<h2><span class="mw-headline" id="Troubleshooting">Troubleshooting</span></h2>
<h3><span class="mw-headline" id="Missing_mdev_supported_types_directory">Missing mdev_supported_types directory</span></h3>
<p>If you have followed instructions and added <code>i915.enable_gvt=1</code> kernel parameter, but there is still no <code>/sys/bus/pci/devices/0000:02:00.0/mdev_supported_types</code> directory, probably your hardware is not supported. Check dmesg log for this message:
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">$ dmesg | grep -i gvt </pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">[    4.227468] [drm] Unsupported device. GVT-g is disabled</pre>
<p>If that is the case, you may want to check upstream for support plans.
For example, for the "Coffee Lake" (CFL) platform support, see <a rel="nofollow"  href="https://github.com/intel/gvt-linux/issues/53">https://github.com/intel/gvt-linux/issues/53</a>
</p>
<h3><span class="mw-headline" id="Windows_hanging_with_bad_memory_error">Windows hanging with bad memory error</span></h3>
<p>If Windows is hanging due to a Bad Memory error look for more details via dmesg. If the logs show something like rlimit memory exceeded, you may need to increase the max memory linux-tosallows qemu to allocate. Assuming you are in the group kvm, adding the following to /etc/security/limits.conf and restarting the PC fixed the errors for me.
</p>
<pre>   # qemu kvm, need high memlock to allocate mem for vga-passthrough
   @kvm	hard	memlock	8388608
   @kvm	soft	memlock	8388608
</pre>
<h2><span class="mw-headline" id="See_also">See also</span></h2>
<ul>
<li><a rel="nofollow"  href="https://github.com/intel/gvt-linux/wiki/GVTg_Setup_Guide">Official GVT-g Setup Guide</a></li>
<li>
<a rel="nofollow"  href="https://github.com/intel/gvt-linux/wiki/Dma_Buf_User_Guide">Official GVT-g DMA-BUF  User Guide</a>.</li>
<li><a rel="nofollow"  href="https://www.reddit.com/r/VFIO/comments/8h352p/guide_running_windows_via_qemukvm_and_intel_gvtg/">Running Windows via QEMU/KVM and Intel GVT-g</a></li>
<li><a rel="nofollow"  href="https://blog.bepbep.co/posts/gvt/">Blog post about using GVT</a></li>
</ul>
</div></div>
		
		<div id="catlinks"  data-mw="interface"><div id="mw-normal-catlinks" class="mw-normal-catlinks">
<a href="../Special:Categories.html" title="Special:Categories">Category</a>: <ul><li><a href="../Category:Virtualization.html" title="Category:Virtualization">Virtualization</a></li></ul>
</div></div>
		<div ></div>
		
	</div>
</div>


		<div id="footer" role="contentinfo" style="margin: 0">
						<ul id="footer-info">
								<li>Retrieved from "<a dir="ltr" href="https://wiki.archlinux.org/index.php?title=Intel_GVT-g&amp;oldid=615265">https://wiki.archlinux.org/index.php?title=Intel_GVT-g&amp;oldid=615265</a>"</li>
		
		<li id="footer-info-lastmod"> This page was last edited on 23 May 2020, at 12:37.</li>
								<li id="footer-info-copyright">Content is available under <a  rel="nofollow" href="http://www.gnu.org/copyleft/fdl.html">GNU Free Documentation License 1.3 or later</a> unless otherwise noted.</li>
							<br>
</ul>
						<ul id="footer-places">
								<li id="footer-places-privacy"><a href="../TOS Wiki:Privacy_policy.html" title="TOS Wiki:Privacy policy">Privacy policy</a></li>
								<li id="footer-places-about"><a href="../TOS Wiki:About.html" title="TOS Wiki:About">About TOS Wiki</a></li>
								<li id="footer-places-disclaimer"><a href="../TOS Wiki:General_disclaimer.html" title="TOS Wiki:General disclaimer">Disclaimers</a></li>
							</ul>
										<ul id="footer-icons" >
										<li id="footer-copyrightico">
											</li>
									</ul>
						<div style="clear: both;"></div>
		</div>
		



