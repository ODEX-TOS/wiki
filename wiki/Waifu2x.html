<!--
    title: Waifu2x
    description: Migration of Waifu2x from the arch Wiki to the TOS Wiki
    published: true
    date: 2020-05-28T17:44:33.000Z
    tags: 
    -->>

<div id="content" class="mw-body" role="main" style="margin: 0">
	<a id="top"></a>
	
	<div class="mw-indicators mw-body-content">
</div>

	<h1 id="firstHeading"  lang="en">Waifu2x</h1>
	
	<div id="bodyContent" class="mw-body-content">
		<div id="siteSub" >From TOS Wiki</div>
		<div id="contentSub"></div>
		
		
		
		<div id="jump-to-nav"></div>
		<a class="mw-jump-link" href="#mw-head">Jump to navigation</a>
		<a class="mw-jump-link" href="#p-search">Jump to search</a>
		<div id="mw-content-text" lang="en" dir="ltr" class="mw-content-ltr"><div class="mw-parser-output">
<p>This article covers installing, using and training <a rel="nofollow"  href="https://github.com/nagadomi/waifu2x">waifu2x</a>, image super-resolution for anime-style art using deep convolutional neural networks.
</p>
<div id="toc" >
<input type="checkbox" role="button" id="toctogglecheckbox"  style="display:none"><div  lang="en" dir="ltr">
<h2>Contents</h2>
<span ><label  for="toctogglecheckbox"></label></span>
</div>
<ul>
<li class="toclevel-1 tocsection-1"><a href="#Installation"><span >1</span> <span >Installation</span></a></li>
<li class="toclevel-1 tocsection-2">
<a href="#Usage"><span >2</span> <span >Usage</span></a>
<ul>
<li class="toclevel-2 tocsection-3"><a href="#Upscaling"><span >2.1</span> <span >Upscaling</span></a></li>
<li class="toclevel-2 tocsection-4"><a href="#Noise_Reduction"><span >2.2</span> <span >Noise Reduction</span></a></li>
<li class="toclevel-2 tocsection-5"><a href="#Upscaling_&amp;_Noise_Reduction"><span >2.3</span> <span >Upscaling &amp; Noise Reduction</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-6">
<a href="#Training"><span >3</span> <span >Training</span></a>
<ul>
<li class="toclevel-2 tocsection-7"><a href="#Dependencies"><span >3.1</span> <span >Dependencies</span></a></li>
<li class="toclevel-2 tocsection-8"><a href="#waifu2x_source"><span >3.2</span> <span >waifu2x source</span></a></li>
<li class="toclevel-2 tocsection-9">
<a href="#Command_line_tools"><span >3.3</span> <span >Command line tools</span></a>
<ul>
<li class="toclevel-3 tocsection-10"><a href="#Noise_Reduction_2"><span >3.3.1</span> <span >Noise Reduction</span></a></li>
<li class="toclevel-3 tocsection-11"><a href="#2x_Upscaling"><span >3.3.2</span> <span >2x Upscaling</span></a></li>
<li class="toclevel-3 tocsection-12"><a href="#Noise_Reduction_+_2x_Upscaling"><span >3.3.3</span> <span >Noise Reduction + 2x Upscaling</span></a></li>
</ul>
</li>
<li class="toclevel-2 tocsection-13">
<a href="#Train_your_own_models"><span >3.4</span> <span >Train your own models</span></a>
<ul>
<li class="toclevel-3 tocsection-14"><a href="#Data_Preparation"><span >3.4.1</span> <span >Data Preparation</span></a></li>
<li class="toclevel-3 tocsection-15"><a href="#Train_a_Noise_Reduction(level1)_model"><span >3.4.2</span> <span >Train a Noise Reduction(level1) model</span></a></li>
<li class="toclevel-3 tocsection-16"><a href="#Train_a_Noise_Reduction(level2)_model"><span >3.4.3</span> <span >Train a Noise Reduction(level2) model</span></a></li>
<li class="toclevel-3 tocsection-17"><a href="#Train_a_2x_UpScaling_model"><span >3.4.4</span> <span >Train a 2x UpScaling model</span></a></li>
<li class="toclevel-3 tocsection-18"><a href="#Train_a_2x_and_noise_reduction_fusion_model"><span >3.4.5</span> <span >Train a 2x and noise reduction fusion model</span></a></li>
</ul>
</li>
</ul>
</li>
<li class="toclevel-1 tocsection-19"><a href="#Docker"><span >4</span> <span >Docker</span></a></li>
<li class="toclevel-1 tocsection-20"><a href="#See_also"><span >5</span> <span >See also</span></a></li>
</ul>
</div>

<h2><span class="mw-headline" id="Installation">Installation</span></h2>
<p>To directly use waifu2x, install <span class="plainlinks archwiki-template-pkg"><a rel="nofollow"  href="https://aur.archlinux.org/packages/waifu2x-git/">waifu2x-git</a></span><sup><small>AUR</small></sup> pakage. There are other alternates for using waifu2x, just search <code>waifu2x</code> in AUR.
</p>
<div class="archwiki-template-box archwiki-template-box-tip">
<strong>Tip:</strong> If you have an NVIDIA GPU, you can install <span class="plainlinks archwiki-template-pkg"><a rel="nofollow"  href="https://www.archlinux.org/packages/?name=cuda">cuda</a></span> to significantly speed up the conversion process.</div>
<h2><span class="mw-headline" id="Usage">Usage</span></h2>
<p>waifu2x is avaliable with command <code>waifu2x</code>. For detailed options, run <code>waifu2x --help</code>
</p>
<h3><span class="mw-headline" id="Upscaling">Upscaling</span></h3>
<p>Use <code>--scale_ratio</code> parameter to specify scale ratio you want. And <code>-i</code> with input file name, <code>-o</code> with output file name:
</p>
<pre>waifu2x --scale_ratio 2 -i my_waifu.png -o 2x_my_waifu.png
</pre>
<h3><span class="mw-headline" id="Noise_Reduction">Noise Reduction</span></h3>
<p>Use <code>--noise_level</code> parameter(<code>1</code> or <code>2</code>) to specify noise reduction level:
</p>
<pre>waifu2x --noise_level 1 -i my_waifu.png -o lucid_my_waifu.png
</pre>
<p>And you can use <code>--jobs</code> to specify number of threads launching at same time, benifit for multi-core CPUÂ :
</p>
<pre>waifu2x --jobs 4 --noise_level 1 -i my_waifu.png -o lucid_my_waifu.png
</pre>
<h3>
<span id="Upscaling_.26_Noise_Reduction"></span><span class="mw-headline" id="Upscaling_&amp;_Noise_Reduction">Upscaling &amp; Noise Reduction</span>
</h3>
<p><code>--scale_ratio</code> and <code>--noise_level</code> can be combined, so you can:
</p>
<pre>waifu2x --scale_ratio 2 --noise_level 1 -i my_waifu.png -o 2x_lucid_my_waifu.png
</pre>
<div class="archwiki-template-box archwiki-template-box-tip">
<strong>Tip:</strong> If you are finding a batch operation interface, you can have a look at this <a rel="nofollow"  href="https://gist.github.com/frantic1048/0970e86c4304b322270edc0ab36dd6a8">waifu2x wrapper script</a>
</div>
<h2><span class="mw-headline" id="Training">Training</span></h2>
<p>To train custom models, <b>an NVIDIA graphical card is required</b> because waifu2x uses <a rel="nofollow"  href="https://developer.nvidia.com/cuda-zone">CUDA</a> for computing. Then you need to prepare below develop dependencies and waifu2x source.
</p>
<h3><span class="mw-headline" id="Dependencies">Dependencies</span></h3>
<p>Install:
</p>
<ul>
<li><span class="plainlinks archwiki-template-pkg"><a rel="nofollow"  href="https://www.archlinux.org/packages/?name=lua51">lua51</a></span></li>
<li><span class="plainlinks archwiki-template-pkg"><a rel="nofollow"  href="https://www.archlinux.org/packages/?name=cuda">cuda</a></span></li>
<li><span class="plainlinks archwiki-template-pkg"><a rel="nofollow"  href="https://www.archlinux.org/packages/?name=snappy">snappy</a></span></li>
<li><span class="plainlinks archwiki-template-pkg"><a rel="nofollow"  href="https://www.archlinux.org/packages/?name=graphicsmagick">graphicsmagick</a></span></li>
<li>
<span class="plainlinks archwiki-template-pkg"><a rel="nofollow"  href="https://aur.archlinux.org/packages/torch7-git/">torch7-git</a></span><sup><small>AUR</small></sup>
</li>
<li>
<span class="plainlinks archwiki-template-pkg"><a rel="nofollow"  href="https://aur.archlinux.org/packages/torch7-trepl-git/">torch7-trepl-git</a></span><sup><small>AUR</small></sup>
</li>
<li>
<span class="plainlinks archwiki-template-pkg"><a rel="nofollow"  href="https://aur.archlinux.org/packages/torch7-sys-git/">torch7-sys-git</a></span><sup><small>AUR</small></sup>
</li>
<li>
<span class="plainlinks archwiki-template-pkg"><a rel="nofollow"  href="https://aur.archlinux.org/packages/torch7-cutorch-git/">torch7-cutorch-git</a></span><sup><small>AUR</small></sup>
</li>
<li>
<span class="plainlinks archwiki-template-pkg"><a rel="nofollow"  href="https://aur.archlinux.org/packages/torch7-nn-git/">torch7-nn-git</a></span><sup><small>AUR</small></sup>
</li>
<li>
<span class="plainlinks archwiki-template-pkg"><a rel="nofollow"  href="https://aur.archlinux.org/packages/torch7-cunn-git/">torch7-cunn-git</a></span><sup><small>AUR</small></sup>
</li>
<li>
<span class="plainlinks archwiki-template-pkg"><a rel="nofollow"  href="https://aur.archlinux.org/packages/torch7-image-git/">torch7-image-git</a></span><sup><small>AUR</small></sup>
</li>
<li>
<span class="plainlinks archwiki-template-pkg"><a rel="nofollow"  href="https://aur.archlinux.org/packages/torch7-xlua-git/">torch7-xlua-git</a></span><sup><small>AUR</small></sup>
</li>
<li>
<span class="plainlinks archwiki-template-pkg"><a rel="nofollow"  href="https://aur.archlinux.org/packages/torch7-dok-git/">torch7-dok-git</a></span><sup><small>AUR</small></sup>
</li>
<li>
<span class="plainlinks archwiki-template-pkg"><a rel="nofollow"  href="https://aur.archlinux.org/packages/torch7-optim-git/">torch7-optim-git</a></span><sup><small>AUR</small></sup>
</li>
<li>
<span class="plainlinks archwiki-template-pkg"><a rel="nofollow"  href="https://aur.archlinux.org/packages/lua51-graphicsmagick-git/">lua51-graphicsmagick-git</a></span><sup><small>AUR</small></sup>
</li>
<li>
<span class="plainlinks archwiki-template-pkg"><a rel="nofollow"  href="https://aur.archlinux.org/packages/lua51-cjson/">lua51-cjson</a></span><sup><small>AUR</small></sup>
</li>
<li>
<span class="plainlinks archwiki-template-pkg"><a rel="nofollow"  href="https://aur.archlinux.org/packages/lua51-csvigo-git/">lua51-csvigo-git</a></span><sup><small>AUR</small></sup>
</li>
<li>
<span class="plainlinks archwiki-template-pkg"><a rel="nofollow"  href="https://aur.archlinux.org/packages/lua51-snappy-git/">lua51-snappy-git</a></span><sup><small>AUR</small></sup>
</li>
</ul>
<p>It is recommended to install below <i>optional</i> <a rel="nofollow"  href="https://developer.nvidia.com/cudnn">cuDNN</a> library and bindings package. With them you can enable cuDNN backend for training, which have a significant speed up.
</p>
<p>You need to manually download a cudnn binary pack from <a rel="nofollow"  href="https://developer.nvidia.com/cudnn">NVIDIA cuDNN site</a> during installing <span class="plainlinks archwiki-template-pkg"><a rel="nofollow"  href="https://www.archlinux.org/packages/?name=cudnn">cudnn</a></span>.
</p>
<ul>
<li>(optional)<span class="plainlinks archwiki-template-pkg"><a rel="nofollow"  href="https://www.archlinux.org/packages/?name=cudnn">cudnn</a></span>
</li>
<li>(optional)<span class="plainlinks archwiki-template-pkg"><a rel="nofollow"  href="https://aur.archlinux.org/packages/torch7-cudnn-git/">torch7-cudnn-git</a></span><sup><small>AUR</small></sup>:</li>
</ul>
<h3><span class="mw-headline" id="waifu2x_source">waifu2x source</span></h3>
<p>Fetch waifu2x source code from GitHub:
</p>
<pre>git clone --depth 1 https://github.com/nagadomi/waifu2x.git
</pre>
<p>Enter source directory. Now you can test waifu2x command line tool:
</p>
<pre>th waifu2x.lua
</pre>
<h3><span class="mw-headline" id="Command_line_tools">Command line tools</span></h3>
<div class="archwiki-template-box archwiki-template-box-note">
<strong>Note:</strong> If you have installed cuDNN library, you can use cuDNN with <code>-force_cudnn 1</code> option. cuDNN is too much faster than default kernel.</div>
<h4><span class="mw-headline" id="Noise_Reduction_2">Noise Reduction</span></h4>
<pre>th waifu2x.lua -m noise -noise_level 1 -i input_image.png -o output_image.png
</pre>
<pre>th waifu2x.lua -m noise -noise_level 0 -i input_image.png -o output_image.png
th waifu2x.lua -m noise -noise_level 2 -i input_image.png -o output_image.png
th waifu2x.lua -m noise -noise_level 3 -i input_image.png -o output_image.png
</pre>
<h4><span class="mw-headline" id="2x_Upscaling">2x Upscaling</span></h4>
<pre>th waifu2x.lua -m scale -i input_image.png -o output_image.png
</pre>
<h4>
<span id="Noise_Reduction_.2B_2x_Upscaling"></span><span class="mw-headline" id="Noise_Reduction_+_2x_Upscaling">Noise Reduction + 2x Upscaling</span>
</h4>
<pre>th waifu2x.lua -m noise_scale -noise_level 1 -i input_image.png -o output_image.png
</pre>
<pre>th waifu2x.lua -m noise_scale -noise_level 0 -i input_image.png -o output_image.png
th waifu2x.lua -m noise_scale -noise_level 2 -i input_image.png -o output_image.png
th waifu2x.lua -m noise_scale -noise_level 3 -i input_image.png -o output_image.png
</pre>
<p>For more, see <a rel="nofollow"  href="https://github.com/nagadomi/waifu2x#command-line-tools">waifu2x#command-line-tools</a>.
</p>
<h3><span class="mw-headline" id="Train_your_own_models">Train your own models</span></h3>
<div class="archwiki-template-box archwiki-template-box-note">
<strong>Note:</strong> If you have installed cuDNN library, you can use cuDNN kernel with <code>-backend cudnn</code> option. And, you can convert trained cudnn model to cunn model with <code>tools/rebuild.lua</code>.</div>
<div class="archwiki-template-box archwiki-template-box-note">
<strong>Note:</strong> The command that was used to train for waifu2x's pretraind models is available at <code>appendix/train_upconv_7_art.sh</code>, <code>appendix/train_upconv_7_photo.sh</code>. Maybe it is helpful.</div>
<h4><span class="mw-headline" id="Data_Preparation">Data Preparation</span></h4>
<p>Genrating a file list.
</p>
<pre>find /path/to/image/dir -name "*.png" &gt; data/image_list.txt
</pre>
<div class="archwiki-template-box archwiki-template-box-note">
<strong>Note:</strong> You should use noise free images.</div>
<p>Converting training data:
</p>
<pre>th convert_data.lua
</pre>
<h4>
<span id="Train_a_Noise_Reduction.28level1.29_model"></span><span class="mw-headline" id="Train_a_Noise_Reduction(level1)_model">Train a Noise Reduction(level1) model</span>
</h4>
<pre>mkdir models/my_model
th train.lua -model_dir models/my_model -method noise -noise_level 1 -test images/miku_noisy.png
# usage
th waifu2x.lua -model_dir models/my_model -m noise -noise_level 1 -i images/miku_noisy.png -o output.png
</pre>
<p>You can check the performance of model with <code>models/my_model/noise1_best.png</code>.
</p>
<h4>
<span id="Train_a_Noise_Reduction.28level2.29_model"></span><span class="mw-headline" id="Train_a_Noise_Reduction(level2)_model">Train a Noise Reduction(level2) model</span>
</h4>
<pre>th train.lua -model_dir models/my_model -method noise -noise_level 2 -test images/miku_noisy.png
# usage
th waifu2x.lua -model_dir models/my_model -m noise -noise_level 2 -i images/miku_noisy.png -o output.png
</pre>
<p>You can check the performance of model with <code>models/my_model/noise2_best.png</code>.
</p>
<h4><span class="mw-headline" id="Train_a_2x_UpScaling_model">Train a 2x UpScaling model</span></h4>
<pre>th train.lua -model upconv_7 -model_dir models/my_model -method scale -scale 2 -test images/miku_small.png
# usage
th waifu2x.lua -model_dir models/my_model -m scale -scale 2 -i images/miku_small.png -o output.png
</pre>
<p>You can check the performance of model with <code>models/my_model/scale2.0x_best.png</code>.
</p>
<h4><span class="mw-headline" id="Train_a_2x_and_noise_reduction_fusion_model">Train a 2x and noise reduction fusion model</span></h4>
<pre>th train.lua -model upconv_7 -model_dir models/my_model -method noise_scale -scale 2 -noise_level 1 -test images/miku_small.png
# usage
th waifu2x.lua -model_dir models/my_model -m noise_scale -scale 2 -noise_level 1 -i images/miku_small.png -o output.png
</pre>
<p>You can check the performance of model with <code>models/my_model/noise1_scale2.0x_best.png</code>.
</p>
<p>For latest information, see <a rel="nofollow"  href="https://github.com/nagadomi/waifu2x#train-your-own-model">waifu2x#train-your-own-model</a>.
</p>
<h2><span class="mw-headline" id="Docker">Docker</span></h2>
<p>See <a rel="nofollow"  href="https://github.com/nagadomi/waifu2x#docker">waifu2x#docker</a>.
</p>
<h2><span class="mw-headline" id="See_also">See also</span></h2>
<ul><li><a rel="nofollow"  href="https://github.com/nagadomi/waifu2x">waifu2x GitHub repository</a></li></ul>
</div></div>
		
		<div id="catlinks"  data-mw="interface"><div id="mw-normal-catlinks" class="mw-normal-catlinks">
<a href="../Special:Categories.html" title="Special:Categories">Category</a>: <ul><li><a href="../Category:Image.html" title="Category:Image">Image</a></li></ul>
</div></div>
		<div ></div>
		
	</div>
</div>


		<div id="footer" role="contentinfo" style="margin: 0">
						<ul id="footer-info">
								<li>Retrieved from "<a dir="ltr" href="https://wiki.archlinux.org/index.php?title=Waifu2x&amp;oldid=571234">https://wiki.archlinux.org/index.php?title=Waifu2x&amp;oldid=571234</a>"</li>
		
		<li id="footer-info-lastmod"> This page was last edited on 15 April 2019, at 04:43.</li>
								<li id="footer-info-copyright">Content is available under <a  rel="nofollow" href="http://www.gnu.org/copyleft/fdl.html">GNU Free Documentation License 1.3 or later</a> unless otherwise noted.</li>
							<br>
</ul>
						<ul id="footer-places">
								<li id="footer-places-privacy"><a href="../TOS Wiki:Privacy_policy.html" title="TOS Wiki:Privacy policy">Privacy policy</a></li>
								<li id="footer-places-about"><a href="../TOS Wiki:About.html" title="TOS Wiki:About">About TOS Wiki</a></li>
								<li id="footer-places-disclaimer"><a href="../TOS Wiki:General_disclaimer.html" title="TOS Wiki:General disclaimer">Disclaimers</a></li>
							</ul>
										<ul id="footer-icons" >
										<li id="footer-copyrightico">
											</li>
									</ul>
						<div style="clear: both;"></div>
		</div>
		



